# -*- coding: utf-8 -*-
"""Modelo_ARIMA_V2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YNeSg-4rtpiFoSO8SqQZFQub3xjx7wgN
"""

pip install pmdarima

!apt-get install git

!git clone https://github.com/TesisMaestria2025/Tesis.git

!pip uninstall -y numpy scipy
!pip install numpy==1.23.5 scipy==1.10.1 --no-cache-dir

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import scipy.stats
import  statsmodels.graphics.tsaplots as sgt
import statsmodels.tsa.stattools as sts
import  statsmodels.tsa.seasonal
from statsmodels.tsa.seasonal import seasonal_decompose
import seaborn as sns
from statsmodels.tsa.arima_model import  ARMA
from statsmodels.tsa.arima_model import  ARIMA
from statsmodels.tsa.statespace.sarimax import  SARIMAX
from pmdarima.arima import  auto_arima
from pmdarima.arima import ADFTest
import warnings
warnings.filterwarnings("ignore")
sns.set()
from typing import Union
from tqdm import tqdm_notebook
from itertools import product
from google.colab import drive
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
from pmdarima.arima import ADFTest
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_squared_error, mean_absolute_error
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.seasonal import seasonal_decompose, STL
from statsmodels.stats.diagnostic import acorr_ljungbox
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.arima_process import ArmaProcess
from statsmodels.graphics.gofplots import qqplot
from statsmodels.tsa.stattools import adfuller
from tqdm import tqdm_notebook
from itertools import product
from typing import Union
import statsmodels.api as sm

# Carga de unidad y datos
drive.mount('/content/drive')
Ruta_Archivo = '/content/drive/MyDrive/Ventas_Hora_V2.csv'

Datos=pd.read_csv(Ruta_Archivo,header=0, sep=";", decimal=".")
Datos.head()

Datos.describe()

Data=pd.DataFrame(Datos.iloc[:, 1])

Data

plt.figure(figsize=(9, 5))
plt.plot(Data,color='black')
plt.title('Serie temporal - Ventas')
plt.xlabel('Cantidad de observaciones')
plt.ylabel('Cantidad de ventas')
plt.savefig('SerieDatos.png')
plt.show()

plt.figure(figsize=(9, 5))
plt.plot(Data[0:100],color='black')
plt.title('Serie temporal - Primeras 100 observaciones')
plt.xlabel('Cantidad de observaciones')
plt.ylabel('Cantidad de ventas')
plt.savefig('SerieDatos.png')
plt.show()

# Elementos constitutivos de la serie
Decomposition = STL(Data, period=12).fit()

plt.figure().figsize=(10,8)
Decomposition.plot()
plt.savefig('Descomposición.png')
plt.show()

plt.figure(figsize=(10, 5))
plt.plot(Data, color='black')
plt.plot(Decomposition.trend, color='red')
plt.title('Serie temporal ventas y tendencia tomada de descomposition')
plt.xlabel('Cantidad de observaciones')
plt.ylabel('Cantidad de ventas')
plt.show()

# Test de evaluación de estacionariedad. Prueba de hipótesis.

ad_fuller_result = adfuller(Data)

print(f'ADF Statistic: {ad_fuller_result[0]}')
print(f'p-value: {ad_fuller_result[1]}')

# Crear el gráfico de autocorrelación
fig, ax = plt.subplots(figsize=(10, 5))  # Ajustar el tamaño del gráfico
plot_acf(Data, lags=40, zero=False, color='black', ax=ax)
ax.set_xlabel('Lags', fontsize=12)  # Título para el eje X
ax.set_ylabel('Autocorrelación', fontsize=12)  # Título para el eje Y
plt.title("Gráfico de Autocorrelación (ACF)", fontsize=14)
plt.show()

# Crear el gráfico de autocorrelación parcial
fig, ax = plt.subplots(figsize=(10, 5))  # Ajustar el tamaño del gráfico
plot_pacf(Data, lags=40, zero=False, color='black', ax=ax)
ax.set_xlabel('Lags', fontsize=12)  # Título para el eje X
ax.set_ylabel('Autocorrelación Parcial', fontsize=12)  # Título para el eje Y
plt.title("Gráfico de Autocorrelación Parcial (PACF)", fontsize=14)
plt.show()

len(Data)

# Separación de datos de entrenamiento y prueba. Se usará 90% de los datos. Esto se usa para identificar en qué observación se encuentra ya el 90%.
Largo=round(len(Data)*0.9,0)

Largo

Train=Data[:2680]
Test=Data[2680:]

# Validación
len(Train), len(Test)

len(Train)+ len(Test)

plt.figure(figsize=(10,5))
plt.plot(Train, color="black", alpha=0.4)
plt.plot(Test, color="red", alpha=0.6)
plt.title("Datos de entrenamiento y prueba", fontsize=14)
plt.show()

# Busqueda mejor modelo
Modelo_ARIMA = auto_arima(Data, start_p = 1, d=0, start_q = 1,
                          max_p = 2, max_q = 2, max_d=0, m =18,
                          start_P = 0, D=0, start_Q=0, max_P=2, max_D=1, max_Q=2,
                          seasonal = True,
                          trace = True,
                          error_action ='ignore',
                          suppress_warnings = True,
                          stepwise = True, n_fits=50)

Modelo1 = SARIMAX(Train,
                order = (1, 0, 4),
                seasonal_order =(1, 0, 1, 18))

Resultado = Modelo1.fit()
Resultado.summary()

# Predicción de los próximos 18 puntos
Predicción = Resultado.forecast(steps=298)

Predicción

len(Predicción)

plt.plot(Predicción, color='red')
plt.plot(Test, color='black')
plt.title('Datos reales vs predicción SARIMA')
plt.xlabel('Cantidad de observaciones')
plt.ylabel('Cantidad de ventas')
plt.savefig('PredicciónArima.png')
plt.show()

# Ajuste para evaluación de errores.
Predicción = Resultado.forecast(steps=298).values

def calculate_mse(predictions, targets):
    mse = np.mean((predictions - targets) ** 2)
    return mse

MSE = calculate_mse(Predicción, Test_ints)
print(f'MSE: {MSE:.2f}')

np.sqrt(MSE)

sum(Test_ints)/len(Test_ints)

plt.plot(Test_ints, color='black')
plt.plot(Predicción, color='red')

plt.plot(Predicción, color='red')