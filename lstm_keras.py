# -*- coding: utf-8 -*-
"""LSTM_Keras.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YjBWefJJ8zpYpsLi3dMPLwZaOUNyxfuB
"""

# Libraries
from google.colab import drive
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, SimpleRNN, GRU
from tensorflow.keras.optimizers import RMSprop # Optimizer
from pickle import load
import math
from sklearn.metrics import mean_squared_error
import numpy as np
from numpy import array
from keras.layers import Bidirectional
from sklearn.preprocessing import StandardScaler
import torch.nn as nn
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, MultiHeadAttention, GlobalAveragePooling1D
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import seaborn as sns
import yfinance as yf

# Load data and print examples
drive.mount('/content/drive')
Ruta_Archivo = '/content/drive/MyDrive/Ventas_Hora_V2.csv'

# Load data
Datos=pd.read_csv(Ruta_Archivo,header=0, sep=";", decimal=",")
Datos.head()

Data=pd.DataFrame(Datos.iloc[:, 1])

Data

plt.figure(figsize=(9, 5))
plt.plot(Data,color='black')
plt.title('Serie temporal - Ventas')
plt.xlabel('Tiempo')
plt.ylabel('Cantidad de ventas')
plt.show()

# Escalar los datos
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(Data)

# Crear secuencias de datos para LSTM
def create_sequences(data, sequence_length):
    sequences = []
    labels = []
    for i in range(len(data) - sequence_length):
        sequences.append(data[i:i+sequence_length])
        labels.append(data[i+sequence_length])
    return np.array(sequences), np.array(labels)

sequence_length = 1  # Longitud de la secuencia
X, y = create_sequences(scaled_data, sequence_length)

X[0], y[0]

# Dividir en conjuntos de entrenamiento, validación y prueba
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)

model = tf.keras.Sequential([
    tf.keras.layers.LSTM(50, activation='relu', return_sequences=False, input_shape=(sequence_length, 1)),
    tf.keras.layers.Dense(1)
])

model.compile(optimizer='adam', loss='mse')

history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))

test_loss = model.evaluate(X_test, y_test)
print(f'Test Loss: {test_loss:.4f}')

predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)
y_test = scaler.inverse_transform(y_test)

plt.figure(figsize=(9, 5))
plt.plot(history.history['loss'], label='Entrenamiento - Loss')
plt.plot(history.history['val_loss'], label='Validación - Loss')
plt.title('Entrenamiento y Validación Loss')
plt.xlabel('Epocas')
plt.ylabel('Loss')
plt.legend()
plt.savefig('Overfitting_LSTM.png')
plt.show()

plt.figure(figsize=(9, 5))
plt.plot(y_test, color='black', label='Datos observados')
plt.plot(predictions,color='red', label='Predicción')
plt.title('Predicción vs datos observados')
plt.xlabel('Tiempo')
plt.ylabel('Cantidad')
plt.legend()
plt.savefig('Ajuste_LSTM.png')
plt.show()

# Suponiendo train_predictions y y_train son numpy arrays
def calculate_rmse(predictions, targets):
    mse = np.mean((predictions - targets) ** 2)
    rmse = np.sqrt(mse)
    return rmse

# Ejemplo de uso
RSME = calculate_rmse(predictions, y_test)
print(f'RMSE: {RSME:.2f}')

Media= np.mean(y_test)
Media

PorcentajeError= (RSME/Media)*100
PorcentajeError